using System;
using System.Collections.Generic;
using System.Collections.Concurrent;
using System.IO;
using System.Threading;
using System.Threading.Tasks;
using SIPSorcery.Net;
using SIPSorceryMedia.Abstractions;
using ChatP2P.Client.Services;

namespace ChatP2P.Client.Services
{
    /// <summary>
    /// üìπ Service de capture vid√©o simple - Interface unifi√©e pour cam√©ra/fichiers
    /// D√©l√®gue le d√©codage r√©el des fichiers vid√©o √† EmguVideoDecoderService
    /// Interface compatible SipSorcery 6.0.11 avec buffer intelligent
    /// </summary>
    public class SimpleVideoCaptureService : IDisposable
    {
        private bool _isCapturing = false;
        private bool _isPlayingFile = false;
        private readonly object _lock = new object();
        private string? _currentVideoFile;
        private SimpleVirtualCameraService? _simpleVirtualCamera;
        private EmguVideoDecoderService? _emguDecoder;

        // ‚úÖ BUFFER SYSTEM: Intelligent frame buffering with bitrate adaptation
        private readonly ConcurrentQueue<VideoFrame> _frameBuffer = new ConcurrentQueue<VideoFrame>();
        private readonly object _bufferLock = new object();
        private int _detectedWidth = 640;
        private int _detectedHeight = 480;
        private int _currentBufferSize = 0;
        private int _maxBufferSize = 30; // Adaptive buffer size
        private int _minBufferSize = 10;
        private double _detectedFrameRate = 15.0;
        private volatile bool _bufferProcessingActive = false;
        private CancellationTokenSource? _bufferCancellation;

        // Events pour notifier de la disponibilit√© des frames vid√©o
        public event Action<VideoFrame>? VideoFrameReady;
        public event Action<string>? LogEvent;
        public event Action<bool>? CaptureStateChanged;

        // ‚úÖ ADAPTIVE: Configuration vid√©o adaptative selon le fichier
        private const int DEFAULT_VIDEO_WIDTH = 640;
        private const int DEFAULT_VIDEO_HEIGHT = 480;
        private double _adaptiveFPS = 15.0; // FPS adaptatif selon la vid√©o
        private int _adaptiveBatchSize = 10; // Taille de lot adaptative
        private DateTime _lastLogTime = DateTime.MinValue;
        private DateTime _lastBatchPreload = DateTime.MinValue;

        public bool IsCapturing => _isCapturing;
        public bool IsPlayingFile => _isPlayingFile;
        public VideoFormat? VideoFormat { get; private set; }
        public bool HasCamera { get; private set; } = false;

        public SimpleVideoCaptureService()
        {
            // üìπ NOUVEAU: D√©tecter la disponibilit√© de la cam√©ra
            DetectCameraAvailability();
            LogEvent?.Invoke($"[VideoCapture] Service initialized - Camera: {(HasCamera ? "Available" : "Not detected")}");
        }

        /// <summary>
        /// D√©tecter si une cam√©ra est disponible
        /// </summary>
        private void DetectCameraAvailability()
        {
            try
            {
                // En production, √©num√©rer les p√©riph√©riques DirectShow/MediaFoundation
                HasCamera = false; // Par d√©faut pas de cam√©ra d√©tect√©e
                LogEvent?.Invoke("[VideoCapture] Camera detection completed");
            }
            catch (Exception ex)
            {
                HasCamera = false;
                LogEvent?.Invoke($"[VideoCapture] No camera detected: {ex.Message}");
            }
        }

        /// <summary>
        /// D√©marrer la capture vid√©o (cam√©ra ou fichier)
        /// </summary>
        public async Task<bool> StartCaptureAsync()
        {
            try
            {
                lock (_lock)
                {
                    if (_isCapturing || _isPlayingFile)
                    {
                        LogEvent?.Invoke("[VideoCapture] Already capturing/playing, ignoring start request");
                        return true;
                    }
                    _isCapturing = true;
                }

                LogEvent?.Invoke("[VideoCapture] ‚ùå No real camera available. Use StartVideoFilePlaybackAsync() for video files.");
                CaptureStateChanged?.Invoke(false);
                return false;
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå Failed to start capture: {ex.Message}");
                CaptureStateChanged?.Invoke(false);
                return false;
            }
        }

        /// <summary>
        /// üé¨ D√©marrer la lecture d'un fichier vid√©o r√©el via EmguVideoDecoderService
        /// Interface simple qui d√©l√®gue le d√©codage complexe au service sp√©cialis√©
        /// </summary>
        public async Task<bool> StartVideoFilePlaybackAsync(string videoFilePath)
        {
            try
            {
                if (!File.Exists(videoFilePath))
                {
                    LogEvent?.Invoke($"[VideoCapture] ‚ùå Video file not found: {videoFilePath}");
                    return false;
                }

                // V√©rifier si c'est un format support√©
                if (!SimpleVirtualCameraService.IsSupportedVideoFile(videoFilePath))
                {
                    LogEvent?.Invoke($"[VideoCapture] ‚ùå Unsupported video format: {Path.GetExtension(videoFilePath)}");
                    return false;
                }

                // Arr√™ter la lecture pr√©c√©dente
                await StopCaptureAsync();

                lock (_lock)
                {
                    _isPlayingFile = true;
                    _currentVideoFile = videoFilePath;
                }

                // ‚úÖ DELEGATE: Use EmguVideoDecoderService for real video processing
                LogEvent?.Invoke($"[VideoCapture] üé¨ Delegating video decoding to EmguVideoDecoderService...");

                _emguDecoder = new EmguVideoDecoderService();
                _emguDecoder.LogEvent += (msg) => LogEvent?.Invoke($"[EmguDecoder] {msg}");

                // Load video file with specialized EmguCV service
                var loaded = await _emguDecoder.InitializeAsync(videoFilePath);
                if (!loaded)
                {
                    LogEvent?.Invoke($"[VideoCapture] ‚ùå EmguVideoDecoderService failed to load: {Path.GetFileName(videoFilePath)}");

                    lock (_lock)
                    {
                        _isPlayingFile = false;
                        _currentVideoFile = null;
                    }
                    return false;
                }

                // ‚úÖ ADAPTIVE: Adapter le FPS et le batch size selon la vid√©o
                AdaptToVideoSpecs();

                // Start intelligent buffered frame processing
                await StartFFmpegCaptureAsync();

                LogEvent?.Invoke($"[VideoCapture] ‚úÖ Video playback started via EmguVideoDecoderService: {Path.GetFileName(videoFilePath)}");
                LogEvent?.Invoke($"[VideoCapture] üìä Video Info: {_emguDecoder.TotalFrames} frames, {_emguDecoder.FrameRate:F1} FPS, {_emguDecoder.Duration:mm\\:ss}");

                return true;
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå Failed to start video file playback: {ex.Message}");
                return false;
            }
        }

        /// <summary>
        /// Callback pour frames de la cam√©ra virtuelle
        /// </summary>
        private void OnVirtualCameraFrameReady(VideoFrame frame)
        {
            VideoFrameReady?.Invoke(frame);
        }

        /// <summary>
        /// ‚úÖ ADAPTIVE: Adapter la configuration selon les sp√©cifications de la vid√©o
        /// </summary>
        private void AdaptToVideoSpecs()
        {
            if (_emguDecoder == null) return;

            // R√©cup√©rer les specs de la vid√©o depuis EmguCV
            _adaptiveFPS = _emguDecoder.FrameRate;
            if (_adaptiveFPS > 0)
            {
                // Adapter le batch size : plus le FPS est √©lev√©, plus le batch est grand
                _adaptiveBatchSize = Math.Max(5, (int)(_adaptiveFPS / 3)); // 1/3 du FPS
            }

            LogEvent?.Invoke($"[VideoCapture] üéØ Adapted to video: {_adaptiveFPS:F1} FPS, batch size: {_adaptiveBatchSize}");
        }

        /// <summary>
        /// Start buffered frame processing using EmguVideoDecoderService
        /// This service manages intelligent buffering and batch processing
        /// </summary>
        private async Task StartFFmpegCaptureAsync()
        {
            try
            {
                if (_emguDecoder == null || !_emguDecoder.IsInitialized)
                {
                    LogEvent?.Invoke("[VideoCapture] ‚ùå EmguCV decoder not initialized");
                    return;
                }

                LogEvent?.Invoke("[VideoCapture] üé¨ Starting intelligent buffered frame processing");

                // Start buffered frame processing in background
                _ = Task.Run(async () => await EmguCaptureLoopAsync());
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå Error starting EmguCV capture: {ex.Message}");
            }
        }

        /// <summary>
        /// ‚úÖ OPTIMIZED: Batch EmguCV processing with intelligent buffering
        /// </summary>
        private async Task EmguCaptureLoopAsync()
        {
            try
            {
                var frameCount = 0;
                var frameInterval = TimeSpan.FromMilliseconds(1000.0 / _adaptiveFPS);

                LogEvent?.Invoke($"[VideoCapture] üöÄ ADAPTIVE EmguCV loop started: {_adaptiveFPS:F1} FPS native, batch size: {_adaptiveBatchSize}");

                // ‚úÖ PRELOAD: D√©marrer avec un pr√©chargement initial
                if (_emguDecoder != null)
                {
                    _ = _emguDecoder.PreloadFrameBatchAsync(0);
                }

                while (_isPlayingFile && _emguDecoder?.IsInitialized == true)
                {
                    try
                    {
                        // ‚úÖ SMART PRELOADING: Pr√©charger les prochaines frames en arri√®re-plan
                        var now = DateTime.UtcNow;
                        if (now - _lastBatchPreload > TimeSpan.FromSeconds(1))
                        {
                            var nextBatchStart = frameCount + _adaptiveBatchSize;
                            _ = _emguDecoder.PreloadFrameBatchAsync(nextBatchStart);
                            _lastBatchPreload = now;
                        }

                        // ‚úÖ NATIVE FPS: Lire une frame au FPS natif de la vid√©o
                        var frameData = await _emguDecoder.ReadFrameAsync(frameCount);

                        if (frameData != null && frameData.Length > 0)
                        {
                            var videoFrame = new VideoFrame
                            {
                                Width = DEFAULT_VIDEO_WIDTH,
                                Height = DEFAULT_VIDEO_HEIGHT,
                                Data = frameData,
                                PixelFormat = VideoPixelFormatsEnum.Rgb,
                                Timestamp = DateTime.UtcNow.Ticks
                            };

                            // √âmettre la frame imm√©diatement
                            VideoFrameReady?.Invoke(videoFrame);

                            frameCount++;

                            // ‚úÖ PERFORMANCE: Logging p√©riodique seulement
                            if (frameCount % (_adaptiveBatchSize * 3) == 0)
                            {
                                LogEvent?.Invoke($"[VideoCapture] üìπ Frame {frameCount} processed (FPS: {_adaptiveFPS:F1})");
                            }
                        }
                        else
                        {
                            // End of video - restart loop
                            frameCount = 0;
                            LogEvent?.Invoke("[VideoCapture] üîÑ Video loop restarted");
                        }

                        // ‚úÖ ADAPTIVE TIMING: Respecter le timing natif du FPS
                        await Task.Delay(frameInterval);
                    }
                    catch (Exception ex)
                    {
                        LogEvent?.Invoke($"[VideoCapture] ‚ö†Ô∏è Frame processing error at frame {frameCount}: {ex.Message}");
                        frameCount++;
                        await Task.Delay(frameInterval);
                    }
                }

                LogEvent?.Invoke("[VideoCapture] üõë ADAPTIVE FFmpeg loop ended");
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå FFmpeg loop error: {ex.Message}");
            }
            finally
            {
                _bufferCancellation?.Cancel();
            }
        }

        /// <summary>
        /// ‚úÖ BUFFER: Adaptive buffer size based on frame rate
        /// </summary>
        private void AdaptBufferSizeToFrameRate(double frameRate)
        {
            // Higher frame rate = larger buffer for smooth playback
            _maxBufferSize = Math.Max(15, (int)(frameRate * 2)); // 2 seconds buffer
            _minBufferSize = Math.Max(5, (int)(frameRate * 0.5)); // 0.5 seconds minimum
        }

        /// <summary>
        /// ‚úÖ BUFFER: Add frames to buffer with overflow protection
        /// </summary>
        private void AddFramesToBuffer(List<VideoFrame> frames)
        {
            lock (_bufferLock)
            {
                foreach (var frame in frames)
                {
                    if (_currentBufferSize >= _maxBufferSize)
                    {
                        // Remove old frames to make space
                        if (_frameBuffer.TryDequeue(out _))
                        {
                            _currentBufferSize--;
                        }
                    }

                    _frameBuffer.Enqueue(frame);
                    _currentBufferSize++;
                }
            }
        }

        /// <summary>
        /// ‚úÖ BUFFER: Process buffered frames at stable rate
        /// </summary>
        private async Task ProcessBufferedFramesAsync(CancellationToken cancellation)
        {
            try
            {
                _bufferProcessingActive = true;
                var targetFrameTime = TimeSpan.FromMilliseconds(1000.0 / _detectedFrameRate);

                while (!cancellation.IsCancellationRequested && _isPlayingFile)
                {
                    if (_frameBuffer.TryDequeue(out var frame))
                    {
                        lock (_bufferLock)
                        {
                            _currentBufferSize--;
                        }

                        // ‚úÖ PERFORMANCE: Dispatch frame to UI without logging
                        VideoFrameReady?.Invoke(frame);
                        await Task.Delay(targetFrameTime, cancellation);
                    }
                    else
                    {
                        // Buffer empty - wait for more frames
                        await Task.Delay(10, cancellation);
                    }
                }
            }
            catch (OperationCanceledException)
            {
                // Normal cancellation
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå Buffer processing error: {ex.Message}");
            }
            finally
            {
                _bufferProcessingActive = false;
            }
        }

        /// <summary>
        /// ‚úÖ PERFORMANCE: Calculate adaptive delay based on buffer level
        /// </summary>
        private int CalculateAdaptiveDelay()
        {
            var bufferRatio = (double)_currentBufferSize / _maxBufferSize;

            if (bufferRatio > 0.8) // Buffer nearly full
            {
                return 100; // Slow down capture
            }
            else if (bufferRatio < 0.3) // Buffer low
            {
                return 10; // Speed up capture
            }
            else
            {
                return 50; // Normal rate
            }
        }

        /// <summary>
        /// ‚úÖ REDUCED LOGGING: Log progress only every 30 seconds
        /// </summary>
        private void LogProgressPeriodically(int frameCount)
        {
            var now = DateTime.UtcNow;
            if (now - _lastLogTime > TimeSpan.FromSeconds(30))
            {
                var position = TimeSpan.FromSeconds(frameCount / _detectedFrameRate);
                LogEvent?.Invoke($"[VideoCapture] üìπ Position: {position:mm\\:ss}, Buffer: {_currentBufferSize}/{_maxBufferSize}");
                _lastLogTime = now;
            }
        }

        /// <summary>
        /// ‚úÖ REDUCED LOGGING: Log restart only periodically
        /// </summary>
        private void LogRestartPeriodically()
        {
            var now = DateTime.UtcNow;
            if (now - _lastLogTime > TimeSpan.FromSeconds(10))
            {
                LogEvent?.Invoke("[VideoCapture] üîÑ Video loop restart");
                _lastLogTime = now;
            }
        }

        /// <summary>
        /// ‚úÖ BUFFER: Get current buffer status for diagnostics
        /// </summary>
        public (int count, int max, double ratio) GetBufferStatus()
        {
            return (_currentBufferSize, _maxBufferSize, (double)_currentBufferSize / _maxBufferSize);
        }

        // ‚ùå REMOVED: No more simulation/test frames - use real videos only


        // ‚ùå REMOVED: No test frame generation - real videos only

        /// <summary>
        /// Arr√™ter la capture vid√©o et/ou lecture de fichier
        /// </summary>
        public async Task StopCaptureAsync()
        {
            try
            {
                lock (_lock)
                {
                    if (!_isCapturing && !_isPlayingFile)
                    {
                        LogEvent?.Invoke("[VideoCapture] Not capturing/playing, ignoring stop request");
                        return;
                    }
                    _isCapturing = false;
                    _isPlayingFile = false;
                    _currentVideoFile = null;
                }

                // Clean up virtual camera if exists
                if (_simpleVirtualCamera != null)
                {
                    await _simpleVirtualCamera.StopPlaybackAsync();
                    _simpleVirtualCamera.Dispose();
                    _simpleVirtualCamera = null;
                }

                // ‚úÖ BUFFER: Stop buffer processing
                _bufferCancellation?.Cancel();

                // Arr√™ter le d√©codeur FFmpeg si actif
                if (_emguDecoder != null)
                {
                    _emguDecoder.Dispose();
                    _emguDecoder = null;
                }

                // ‚úÖ BUFFER: Clear buffer
                lock (_bufferLock)
                {
                    while (_frameBuffer.TryDequeue(out _)) { }
                    _currentBufferSize = 0;
                }

                LogEvent?.Invoke("[VideoCapture] ‚úÖ Video capture/playback stopped");
                CaptureStateChanged?.Invoke(false);
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå Error stopping capture: {ex.Message}");
            }
        }

        /// <summary>
        /// Obtenir la liste des p√©riph√©riques vid√©o disponibles
        /// </summary>
        public static async Task<string[]> GetAvailableVideoDevicesAsync()
        {
            try
            {
                // En VM, lister les p√©riph√©riques simul√©s pour debugging
                var devices = new List<string>();

                // TODO: En production, √©num√©rer DirectShow devices ou MediaFoundation
                devices.Add("üìπ Default Camera");
                devices.Add("üñ•Ô∏è Screen Capture");
                devices.Add("üìÅ Video File Playback");

                return devices.ToArray();
            }
            catch (Exception ex)
            {
                // En cas d'erreur, retourner au moins le mode simulation
                return new[] { $"‚ö†Ô∏è Error detecting video: {ex.Message}", "üìπ Simulation Mode Available" };
            }
        }

        /// <summary>
        /// Changer la r√©solution vid√©o
        /// </summary>
        public async Task<bool> ChangeResolutionAsync(int width, int height, int fps)
        {
            try
            {
                LogEvent?.Invoke($"[VideoCapture] Resolution changed to: {width}x{height}@{fps}fps (simulated)");
                return true;
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå Error changing resolution: {ex.Message}");
                return false;
            }
        }

        public void Dispose()
        {
            try
            {
                StopCaptureAsync().Wait(1000);
                _simpleVirtualCamera?.Dispose();
                _emguDecoder?.Dispose();
                LogEvent?.Invoke("[VideoCapture] Service disposed");
            }
            catch (Exception ex)
            {
                LogEvent?.Invoke($"[VideoCapture] ‚ùå Error during dispose: {ex.Message}");
            }
        }
    }

    /// <summary>
    /// Structure pour repr√©senter une frame vid√©o
    /// </summary>
    public class VideoFrame
    {
        public int Width { get; set; }
        public int Height { get; set; }
        public byte[] Data { get; set; } = Array.Empty<byte>();
        public VideoPixelFormatsEnum PixelFormat { get; set; }
        public long Timestamp { get; set; }
    }
}